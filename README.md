
# Medical Charts ETL

## Description  
The Medical Charts ETL Project is a comprehensive solution for tracking and managing the movement of medical chart data across various systems, including SQL tables, Windows directories, and CSV files. The project automates the extraction, transformation, and loading (ETL) processes, ensuring seamless updates to SQL Server tables.
Key highlights include an end-to-end automation workflow triggered by file drops. This project is designed to be robust, scalable, and easy to configure for different environments.

## Table of Contents
- [Description](#description)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [License](#license)
- [Authors](#authors)
- [Acknowledgments](#acknowledgments)

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/Har-Var/Medical-Charts-ETL.git
   cd Medical-Charts-ETL
   ```
2. Ensure you have Python 3.x installed.
3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```
4. Configure the config_sample.py file at `src\config\config_sample.py` as per your environment. Rename the file to `config.py`
5. Ensure you have Microsoft Excel installed (version supporting macros)
6. Enable macros in Excel:
   - Go to `File > Options > Trust Center > Trust Center Settings`.
   - Enable "Trust access to VBA project object model."
7. Install SQL Server Management Studio (SSMS)
   - Download and install SSMS from the official Microsoft website:  
      [Download SSMS](https://aka.ms/ssmsfullsetup)
   - Launch SSMS and connect to your SQL Server instance using your credentials.
8. Create a database named `MedicalChartsETL` in SQL Server by executing `sql_scripts\create_EntireDatabase_MedicalChartsETL.sql` in SSMS

## Usage
Run the demo notebook `end_to_end_demo.ipynb` in the `notebooks` folder.

## Features
- **End-to-End Automation**: Trigger-based automation for multiple processes. Automated file movement, logging, notification messages, and more to support ETL workflows.
- **Slack Notifications**: Sends real-time updates for process statuses using Slack channels. Supports custom messages for error handling and success logs.
- **Multi-Platform Chart Tracking**: Track medical charts across Windows directories, CSV files, and SQL Server tables.
- **Dynamic Path Management**: Automatically manages folder structures for staging, input, logging, and archival processes. Ensures directories are created dynamically during initialization.
- **Scalability**: Designed to handle multiple vendors (e.g., Gryff, Huffle, Raven) with vendor-specific configurations. Process can even handle new vendor additions, without modifying the main codebase. 
- **Modularity**: Modular codebase for easy addition of new processes or integrations.

## Project Structure
The project is organized into the following folders:

* `src`: Contains the source code for the project.
	+ `automation`: Contains the automation scripts.
		- `automation_utils.py`: Contains utility functions for the automation process.
      - `recon_report_load.py`: Contains the code for the Recon Report Load automation.
      - `recon_report_update.py`: Contains the code for the Recon Report Update automation.
      - `slack_messages.py`: Contains the code for sending Slack messages.
	+ `dataprep`: Contains the code for generating Reports and Charts data.
      + `charts`: Contains the codes for creating & incrementing charts and pushing them to Windows, CSV and SQL Locations.
      + `reports`: Contains the codes for generating daily reports txt.
	+ `utils`: Contains utility functions for the project.
   + `config`: Contains configuration files for the project.
* `requirements.txt`: Contains the dependencies required by the project.
* `data`: Contains the all data files generated by the process.
   + `reports`: Stores all the daily reports.
   + `charts`: Stores all charts whether as .json in `charts_drop_off` location or as .csv in `payment_reconciliation`. Also stores stats for increment push in `resources`. 
* `notebooks`: Contains Jupyter Notebook - `end_to_end_demo.ipynb` for end-to-end demo.
* `sql_scripts`: Contains SQL scripts for creating database and loading data into it.
   + `create_EntireDatabase_MedicalChartsETL.sql`: Creates the entire database along with all the required database objects.
   + `<rest folders in the directory>`: the above script is further divided into seperate objects which are organized into seperate folders.
   + `queries`: Some adhoc SQL scripts for querying the database. 
* `automation`: Contains the locations that manage the automation flow.
   + `<process_name>`: Either `recon_report_load` or `recon_report_update`
      + `staging`: Serves as the staging area. Primarily used for storing reports for `recon_report_load` process.
      + `input`: This is the monitoring area. Copy files here to trigger the automation.
      + `input_archive`: The files that triggered the process move here after the automation kicks-off.
      + `log`: Stores all the log files.
      + `trigger`: Holds the trigger file for the process. Exists only for `recon_report_update` process. Copy and paste this file to the monitoring folder to start the process.
* `excel_setup`: Contains the Excel setup file `financial_reconciliation_reports.xlsm` for generating payment reconciliation csv reports.


## Contributing
Contributions are welcome! Please submit a pull request with any improvements.

## License
This project is licensed under the MIT License.

## Authors
- [Har-Var](https://github.com/Har-Var)

## Acknowledgments
Thanks to everyone who helped me test and improve upon this project. This work draws inspiration from one of the project I delivered at my previous organizaiton.
